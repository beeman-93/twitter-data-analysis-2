{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db0f6ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clustering using K-means method\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import glob\n",
    "import re\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0e4c881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV.file\n",
    "df=pd.read_csv('preprocess1.csv')\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a22f856b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lv/fc005q_d2fx0299s750b5vw00000gn/T/ipykernel_7883/1366370625.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Round1']=df['Translated'].str.replace('[^\\w\\s#@/:%.,_-]', '', flags=re.UNICODE)\n"
     ]
    }
   ],
   "source": [
    "# Round1: Remove the emoji\n",
    "df['Round1']=df['Translated'].str.replace('[^\\w\\s#@/:%.,_-]', '', flags=re.UNICODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33c63947",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lv/fc005q_d2fx0299s750b5vw00000gn/T/ipykernel_7883/588299801.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Round2']=df['Round1'].str.replace('[^\\w\\s]','')\n"
     ]
    }
   ],
   "source": [
    "# Round2: Remove punctuation: \",\" , \"'\", \"...\"\n",
    "df['Round2']=df['Round1'].str.replace('[^\\w\\s]','')\n",
    "#print(df['Round2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1883a5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round3: We lowercase the capitalized words\n",
    "df ['Round3']= df['Round2'].str.lower()\n",
    "#print (df['Round3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8129f10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "allow_postags = set(['NOUN', 'VERB', 'ADJ', 'ADV', 'PROPN'])\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "930d3ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round4: Remove stopwords and lemmatization \n",
    "txt2=list(df['Round3'])\n",
    "join_words_list=[]\n",
    "for element in txt2:\n",
    "    words=nlp(element)\n",
    "    words_list=[]\n",
    "    for token in words:\n",
    "        if token.text not in stop_words and token.pos_ in allow_postags:\n",
    "            words_list.append(token.lemma_)\n",
    "    for word in words_list:\n",
    "        join_words =' '.join(words_list)\n",
    "    join_words_list.append(join_words)\n",
    "\n",
    "df['Round4']=join_words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f44f295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Date, User, Round4 to make a new dataframe\n",
    "df_clean = df[['Date','User','Round4']]\n",
    "descriptions = df_clean['Round4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48c1d3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization using tf-idf\n",
    "# Term frequency–inverse document frequency, \n",
    "# is a numerical statistic that is intended to reflect \n",
    "# how important a word is to a document in a collection or corpus.\n",
    "# how to calculate?\n",
    "# the frequency of one word appears in one document multiplies LOG(the frequency of the document that contains that word appears in all of the documents)\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "                            \n",
    "                                max_features=100,\n",
    "                                max_df=0.8,\n",
    "                                min_df=5,\n",
    "                                ngram_range = (1,3),\n",
    "                    \n",
    "\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f62be94",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = vectorizer.fit_transform(df['Round4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "576e73af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danmengcai/opt/anaconda3/envs/newPy/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "dense = tfidf.todense()\n",
    "denselist = dense.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55c4e31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good night let leave nagi go sleep draw almost year start draw nagi first time long time often draw middle night write lot go bed moment remember nagi maybe difficult situation synchronize\n",
      "['first', 'first time', 'go', 'good', 'leave', 'let', 'long', 'lot', 'maybe', 'night', 'sleep', 'start', 'time', 'year']\n"
     ]
    }
   ],
   "source": [
    "all_keywords = []\n",
    "for description in denselist:\n",
    "    x=0\n",
    "    keywords = []\n",
    "    for word in description:\n",
    "        if word > 0:\n",
    "            keywords.append(feature_names[x])\n",
    "        x=x+1\n",
    "    all_keywords.append(keywords)\n",
    "print (descriptions[0])\n",
    "print (all_keywords[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e663b100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(max_iter=100, n_clusters=5, n_init=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(max_iter=100, n_clusters=5, n_init=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(max_iter=100, n_clusters=5, n_init=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The K-means algorithm in data mining starts with a first group of randomly selected centroids, which are used as the beginning points for every cluster, \n",
    "# and then performs iterative (repetitive) calculations to optimize the positions of the centroids\n",
    "# It halts creating and optimizing clusters when either:\n",
    "# The centroids have stabilized — there is no change in their values because the clustering has been successful.\n",
    "# The defined number of iterations has been achieved.\n",
    "\n",
    "true_k = 5\n",
    "model = KMeans(n_clusters=true_k, init=\"k-means++\", max_iter=100, n_init=1)\n",
    "model.fit(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a38f0c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the result in a txt.file  \n",
    "\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "with open (\"/Users/danmengcai/Desktop/Folders/PyPractice/japanese_tweets_analysis/results.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for i in range(true_k):\n",
    "        f.write(f\"Cluster {i}\")\n",
    "        f.write(\"\\n\")\n",
    "        for ind in order_centroids[i, :10]:\n",
    "            f.write (' %s' % terms[ind],)\n",
    "            f.write(\"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dad4841",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
